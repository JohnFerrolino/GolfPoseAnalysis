{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic # Holistic model\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing utilities\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # COLOR CONVERSION BGR 2 RGB\n",
    "    image.flags.writeable = False                  # Image is no longer writeable\n",
    "    results = model.process(image)                 # Make prediction\n",
    "    image.flags.writeable = True                   # Image is now writeable \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR COVERSION RGB 2 BGR\n",
    "    return image, results\n",
    "\n",
    "def extract_keypoints1(results, pos):\n",
    "    #Arm\n",
    "    leftWrist = np.array([[res.x, res.y, 1] for res in [results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_WRIST.value]]]).flatten() if results.pose_landmarks else np.zeros(4)\n",
    "    rightWrist = np.array([[res.x, res.y, 1] for res in [results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_WRIST.value]]]).flatten() if results.pose_landmarks else np.zeros(4)\n",
    "\n",
    "    leftElbow = np.array([[res.x, res.y, 1] for res in [results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_ELBOW.value]]]).flatten() if results.pose_landmarks else np.zeros(4)\n",
    "    rightElbow = np.array([[res.x, res.y, 1] for res in [results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_ELBOW.value]]]).flatten() if results.pose_landmarks else np.zeros(4)\n",
    "\n",
    "    leftShoulder = np.array([[res.x, res.y, 1] for res in [results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER.value]]]).flatten() if results.pose_landmarks else np.zeros(4)\n",
    "    rightShoulder = np.array([[res.x, res.y, 1] for res in [results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER.value]]]).flatten() if results.pose_landmarks else np.zeros(4)\n",
    "\n",
    "    #Body\n",
    "    leftShoulderBody = np.array([[res.x, res.y, 1] for res in [results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER.value]]]).flatten() if results.pose_landmarks else np.zeros(4)\n",
    "    rightShoulderBody = np.array([[res.x, res.y, 1] for res in [results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_SHOULDER.value]]]).flatten() if results.pose_landmarks else np.zeros(4)\n",
    "\n",
    "    leftHipBody = np.array([[res.x, res.y, 1] for res in [results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_HIP.value]]]).flatten() if results.pose_landmarks else np.zeros(4)\n",
    "    rightHipBody = np.array([[res.x, res.y, 1] for res in [results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_HIP.value]]]).flatten() if results.pose_landmarks else np.zeros(4)\n",
    "\n",
    "    leftKneeBody = np.array([[res.x, res.y, 1] for res in [results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_KNEE.value]]]).flatten() if results.pose_landmarks else np.zeros(4)\n",
    "    rightKneeBody = np.array([[res.x, res.y, 1] for res in [results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_KNEE.value]]]).flatten() if results.pose_landmarks else np.zeros(4)\n",
    "\n",
    "    #LowerBody\n",
    "    leftHipLower = np.array([[res.x, res.y, 1] for res in [results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_HIP.value]]]).flatten() if results.pose_landmarks else np.zeros(4)\n",
    "    rightHipLower = np.array([[res.x, res.y, 1] for res in [results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_HIP.value]]]).flatten() if results.pose_landmarks else np.zeros(4)\n",
    "\n",
    "    leftKneeLower = np.array([[res.x, res.y, 1] for res in [results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_KNEE.value]]]).flatten() if results.pose_landmarks else np.zeros(4)\n",
    "    rightKneeLower = np.array([[res.x, res.y, 1] for res in [results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_KNEE.value]]]).flatten() if results.pose_landmarks else np.zeros(4)\n",
    "\n",
    "    leftAnkleLower = np.array([[res.x, res.y, 1] for res in [results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_ANKLE.value]]]).flatten() if results.pose_landmarks else np.zeros(4)\n",
    "    rightAnkleLower = np.array([[res.x, res.y, 1] for res in [results.pose_landmarks.landmark[mp_pose.PoseLandmark.RIGHT_ANKLE.value]]]).flatten() if results.pose_landmarks else np.zeros(4)\n",
    "    \n",
    "    golfdataset = pd.DataFrame([[leftWrist[0], leftWrist[1], rightWrist[0], rightWrist[1], leftElbow[0], leftElbow[1], rightElbow[0], rightElbow[1], leftShoulder[0], leftShoulder[1], rightShoulder[0], rightShoulder[1], leftShoulderBody[0], leftShoulderBody[1], rightShoulderBody[0], rightShoulderBody[1], leftHipBody[0], leftHipBody[1], rightHipBody[0], rightHipBody[1], leftKneeBody[0], leftKneeBody[1], rightKneeBody[0], rightKneeBody[1], leftHipLower[0], leftHipLower[1], rightHipLower[0], rightHipLower[1], leftKneeLower[0], leftKneeLower[1], rightKneeLower[0], rightKneeLower[1], leftAnkleLower[0], leftAnkleLower[1], rightAnkleLower[0], rightAnkleLower[1], leftWrist[2]]], columns=['x1', 'y1', 'x2', 'y2', 'x3', 'y3', 'x4', 'y4', 'x5', 'y5', 'x6', 'y6', 'x7', 'y7', 'x8', 'y8', 'x9', 'y9', 'x10', 'y10', 'x11', 'y11', 'x12', 'y12', 'x13', 'y13', 'x14', 'y14', 'x15', 'y15', 'x16', 'y16', 'x17', 'y17', 'x18', 'y18', \"Label\"])\n",
    "    golfdataset.to_csv('GolfSEDataset.csv', mode='a', index=False, header=False)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 37\u001b[0m\n\u001b[0;32m     35\u001b[0m     cv2\u001b[39m.\u001b[39mputText(annotated_image, \u001b[39m\"\u001b[39m\u001b[39maaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\u001b[39m\u001b[39m\"\u001b[39m, (\u001b[39m200\u001b[39m,\u001b[39m200\u001b[39m), cv2\u001b[39m.\u001b[39mFONT_HERSHEY_COMPLEX, \u001b[39m0.5\u001b[39m, (\u001b[39m0\u001b[39m, \u001b[39m255\u001b[39m, \u001b[39m0\u001b[39m), \u001b[39m1\u001b[39m, cv2\u001b[39m.\u001b[39mLINE_AA)\n\u001b[0;32m     36\u001b[0m     cv2\u001b[39m.\u001b[39mimshow(\u001b[39m'\u001b[39m\u001b[39mPose Detection\u001b[39m\u001b[39m'\u001b[39m, annotated_image)\n\u001b[1;32m---> 37\u001b[0m \u001b[39mif\u001b[39;00m cv2\u001b[39m.\u001b[39;49mwaitKey(\u001b[39m0\u001b[39;49m) \u001b[39m&\u001b[39m \u001b[39m0xFF\u001b[39m \u001b[39m==\u001b[39m \u001b[39mord\u001b[39m(\u001b[39m'\u001b[39m\u001b[39me\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     38\u001b[0m     cv2\u001b[39m.\u001b[39mdestroyAllWindows()\n\u001b[0;32m     39\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Set up Mediapipe Pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "# Set minimum confidence levels\n",
    "min_detection_confidence = 0.2\n",
    "min_tracking_confidence = 0.2\n",
    "\n",
    "# Define the path to the directory containing the images\n",
    "image_dir = './Dataset/Takeaway/'\n",
    "\n",
    "# Get a list of all the image filenames in the directory\n",
    "image_filenames = [os.path.join(image_dir, filename) for filename in os.listdir(image_dir)\n",
    "                   if os.path.isfile(os.path.join(image_dir, filename))]\n",
    "\n",
    "# Loop over each image filename\n",
    "for filename in image_filenames:\n",
    "    # Read in the image\n",
    "    image = cv2.imread(filename)\n",
    "    image = cv2.resize(image,(700,700))\n",
    "\n",
    "    # Convert the image to RGB\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Detect the pose\n",
    "    with mp_pose.Pose(min_detection_confidence=min_detection_confidence,\n",
    "                      min_tracking_confidence=min_tracking_confidence) as pose:\n",
    "        results = pose.process(image)\n",
    "\n",
    "        # Draw the pose landmarks on the image\n",
    "        annotated_image = image.copy()\n",
    "        mp_drawing.draw_landmarks(annotated_image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "        # Display the annotated image\n",
    "        cv2.putText(annotated_image, \"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\", (200,200), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "        cv2.imshow('Pose Detection', annotated_image)\n",
    "    if cv2.waitKey(0) & 0xFF == ord('e'):\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "    # Close the window\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a6c65b64b590a34e1d6ebc3627c0de0b07067093c8d586f518ef74d173175f1a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
